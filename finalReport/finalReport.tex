%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  FINAL REPORT - A TEMPLATE
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[final]{cmpreport_02}


% Some package I am using. You may not need them
%
\usepackage{rotating}
\usepackage{subfloat}
\usepackage{color}
\usepackage{pdfpages}
\usepackage{cleveref}
\usepackage{natbib}
\usepackage{float}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}



%\setkeys{Gin}{draft}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  Fill in the fields with:
%
%  your project title
%  your name
%  your registration number
%  your supervisor's name
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Robot Mower Mapping and Pathing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% The author's name is ignored if the following command 
% is not present in the document
%
% Before submitting a PDF of your final report to the 
% project database you may comment out the command
% if you are worried about lack of anonimity.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Toby William Towler}

\registration{100395626}
\supervisor{Edwin Ren}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Fill in the field with your module code.
% this should be:
%
% for BIS project module   -> CMP-6012Y
% for CS project module    -> CMP-6013Y
% for MComp project module -> CMP-7043Y
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ccode{CMP-6013Y}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Comment out if confidential report.
% The command should be used if the project is subjected 
% to a Non Disclosure Agreement.
%
% Three examples of the use of the \confidential command. 
% Please ask your supervisor what confidential statement 
% should be used, if appropriate.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\confidential{}

%\confidential{The contents of this report remain confidential for two years and should not be discussed or disclosed to any third party without the prior written permission from the School of Computing Sciences, the University of East Anglia}

%\confidential{The information contained in this document is confidential, privileged and only for the information of the intended recipient and may not be used, published or redistributed without the prior written consent of FruitName Ltd}

\summary{
The abstract of your report summarises your entire work () in no more than half a page. It should include the context of your work including its main objective, what methods you employed, how you implemented these, what the outcomes were and a final statement as a conclusion. It should not contain acronyms, abbreviations, elements of a literature review (though a statement of related work is permissible if it is crucial to your work) or future work. The abstract should be written when everything else has been written up and the project is finished! is this workng
}

\acknowledgements{
    Edwin Ren, Eden Attlebourgh
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% If you do want a list of figures and a list of tables
% to appear after the table of contents then comment this line.
% THIS IS NOT ADVISED THOUGH AS IT COUNTS FOR YOUR 40 PAGES!
%
% Note that the class file contains code to avoid
% producing an empty list section (e.g list of figures) if the 
% list is empty (i.e. no figure in document).
%
% The command also prevents inserting a list of figures or tables 
% anywhere else in the document
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\nolist

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Comment out if you want your list of figures and list of
% tables on one page instead of two or more pages, in particular 
% if the lists do not fit on a single page.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\onePageLists


\begin{document}

\section{Introduction}

The robot mower is an already existing project developed by previous masters students from the University of East Anglia.
Physically, the mower has 2 tracks for movement on the sides of a metal frame, it is controlled by raspberry pi 4 running the Robot Operating System \citep{doi:10.1126/scirobotics.abm6074}.
Sensor wise, the robot is equipped with a 4G dongle, lidar and a GPS chip that was upgraded to an RTK chip in this iteration of the project.
The existing code base was mostly written in python with very small amounts of C++.
Because of this, all of my code will be written in python to slot into existing code without issue.

My contribution to this project this year will be, regarding the overall movement and guidance of the robot.
For ease of planning, I have broken this down into 3 sections:
\begin{enumerate}
	\item Basic map generation
	\item complete coverage path planning
	\item map generation from an aerial image
\end{enumerate}

These sections are all modular meaning they can be developed, tested and function independently but still easily be integrated together for the final product.
The specified use case of the robot will now be to cut golf courses, this is particularly relevant to the aerial map generation section of my work which will likely use a machine learning model and require relevant training data, while the other sections are not concerned with a real world use case as their algorithms will work be able to tweaked for any applicable use case of this robot.





\section{Background and Related Work}

Another section that is essential and should keep its title as is! Although you could perhaps call it ``Literature Review'' instead, this is not advisable as at this stage of your project we do not expect an extensive literature review since this was already done in the second formative assignment. The rationale is simply because you will lose valuable pages that could be used better in the next two sections that will cover the preparation and implementation of actual work done. So just provide the context in which your project operates here, and then provide a brief overview of similar work that is directly relevant to yours. Try to avoid blatant copying and pasting from the formative literature review as it is bound to read awkwardly.

\section{System Design}

\subsection{Map Generation}
Map generation is an important part of testing this system, it is important to test on all scenarios that may occur in the real world.
For this reason, random or parameter based map generation is very necessary to guarantee success in every environment.
As the outputs of this section will mostly be used for testing the path planning algorithm on regions with differing area, number of corners and complexity, no excessive algorithmic complexity is needed.
This program should also be able to create n obstacles within the main field, such areas would represent obstructions in the mowers desired path, for example trees or telephone poles in the real world.
This means we need a function with 2 parameters:

\begin{itemize}
	\item K, number of angles in the outer field
	\item N, number of obstacles within the field, since it would not be sensible to take a parameter for the number of corners for every hole, we can generate them randomly assuming 3â€“8 corners staying inline with the complexity of the rest of the field without being unreasonably overengineered.
\end{itemize}


\subsubsection{Corners}
The number and distance between corners could be thought to represent complexity of a shape.
The number of corners in a shape

KEEPGOING

\subsubsection{Obstacles}
Obstacles or holes, can be thought to represent real world obstructions for example trees or telephone poles in a real field.
Generation of obstacles can be completed using the same function as the outer field generation, simply with different parameters.
The algorithm \ref{mg:genPoints} takes 3 parameters, number of points in the shape, an origin point and the range new points.
This allows for variable size, positioning and complexity.


\subsubsection{Graham Scan}
The Graham Scan \citep{graham1972efficient} is an algorithm to find convex hulls, that is from a set of points the outline which contains all inner points.
This algorithm does this by sorting the points by their polar angle to the lowest point, since this is always in the hull.
There is then further calculations based on the angle between adjacent points to omit inner points from the outline, however for this use case that is not necessary since all points will be vertexes in a field.
For this reason, the algorithm used is not strictly a Graham Scan but rather heavily based on the first stage, as shown in \ref{mg:sortPoints}
Using this algorithm allows for consistent outlining of any set of points with no crossovers or intersections

\subsection{Complete Coverage Path Planning}
Complete coverage path planning(CCPP) is "the task of determining a path that passes over all points of an area or volume of interest while avoiding obstacles" \citep{zhao2023complete}
For this module, I have used the Fields2Cover library \citep{fields2cover}, this library is open source.
During the course of this project, I contributed to his library, fixing a bug during the build process.
The library splits the task up into several sub-tasks.


\subsubsection{Robot Configuration}
Robot sizing has 2 important factors, track width, how wide the machine itself is, and blade width, how wide the utility object is.
For farming equipment the utility object is usually larger than the vehicle, for example a combine harvester's wheels being narrower than blade, however for this project the blade is within the tracks.
For this reason the functions will compute slightly differently to its probable intended use case as the tracks are likely to overlap however this should not cause an issue and all outputs should function as needed.

The robot has 2 more parameters regarding its turning circle, these are minimum turning radius and maximum differential curvature.
Both of these are important when calculating a path for the robot to follow as they ensure the robot can easily follow the path.

The robot is 22cm wide from outer edge to edge and the gap between the tracks is 17cm, with a track width of roughly 2.5cm.


\subsubsection{Headland Generation}
Headlands are the area in which a vehicle turns, think of the rough edges of a crop field, these exist so that agricultural vehicles do not trample their crops when turning.
Although for the use case of a golf course this is not strictly needed as there are no "crops" or areas the robot cannot touch
Headlands are also generated around obstacles to allow for suitable turning area around the obstacles if needed, this serves as an area to do a "U-turn", effectively the same as reaching the end of the field.

KEEPGOING



\subsubsection{Swath Generation}
Swaths are the individual straight lines that make up the complete path,
they are often parallel to each other, but this can vary depending on how the shape of the field is segmented into smaller shapes however they will always be parallel while in the same sub area.
There are 2 ways of determining the optimal angle; the sum of the lengths of all swaths, or the number of swaths, where lower is better for each.
Both of these have pros and cons, for example lower total length offers better time efficiency assuming a near constant travel speed while lower swath count gives reduced turning movements which can be better if turning requires a slower speed or other complexities.
Similarly, lower sum length of course means less distance travelled and usually less fuel/energy consumed, however the opposite can be true if the acceleration and deceleration causes greater energy consumption compared to constant velocity.
Swaths are generated within the bounds of the headlands to allow for independent handling of the turning and connection of swaths regardless of the rest of the generation process.
To find the best angle, each angle is tested and compared. This brute force approach could be considered slow, but it is all the library offers and could be taken into consideration in a future release.

\subsubsection{Route Planning}
A route is the order in which swaths will be covered.
These can be sorted in a number of ways:

\begin{itemize}
	\item{Shortest route to cover all swaths, order depends on field}
	\item{Boustrophedon order, a zigzag like pattern covering swaths in order (1,2,3...)}
	\item{Snake order, Similar to Boustrophedon but skipping 1 swath each time (1,3,5...)}
	\item{Spiral order, a spiral pattern around the field, first swath then last (1, n, 2, n-1...)}
	\item{Custom order, user defined}
\end{itemize}


KEEPGOING

\subsubsection{Path Planning}
Path planning refers to the connection of all swaths in route order.
There are a couple of ways the to link neighbouring swaths, these are the Dubins curve and Reeds-Shepp curve.

% \begin{itemize}
% 	\item{Dubins Curve}
% 	\item{Reeds-Shepp curve}
% \end{itemize}

Both of these compute the shortest path between the 2 points, with the deciding factor between the 2 is the robots ability to move backwards.
Reeds-Shepp allows backwards movement


\subsubsection{Cell Decomposition}






\subsection{Aerial Map Generation}
Previously, for the program to take in a real world map from an image of the real world, the user would have to upload the picture and manually trace the outline, this could cause some problems.
For example, the outline is only as accurate as the user's mouse placement, likely skipping some smaller corners to save time or due to inability to be accurate to the necessary degree.
Automating this labourious and time consuming task would positively increase user experience and usability, this can be done using algorithmic and machine learning approaches.

\subsubsection{Algorithmic Approaches}
There are several algorithmic methods that try to achieve this task from several different librarys. A popular library for image processing is scikit-image.

OpenCV's Canny edge detection implementation \citep{opencv_library} follows the classic algorithm developed by Canny \citep{canny1986computational}.
The algorithm works through several steps to detect edges in images:
\begin{itemize}
	\item Gaussian Blur: First, the image is smoothed with a Gaussian filter to reduce noise, as edge detection is highly sensitive to noise.
	\item Gradient Calculation: The algorithm calculates the intensity gradients of the image using Sobel filters in both horizontal and vertical directions:
	\item Non-maximum Suppression: This step thins out the edges by keeping only the local maxima. For each pixel, it checks if it's a local maximum in the direction of the gradient. If not, it's suppressed (set to zero).
	\item Double Thresholding: The algorithm applies two thresholds:
	      \begin{itemize}
		      \item High threshold: Pixels above this are considered "strong" edges
		      \item Low threshold: Pixels between low and high are considered "weak" edges
	      \end{itemize}
	\item Edge Tracking by Hysteresis: Finally, weak edges that are connected to strong edges are kept, while isolated weak edges are discarded. This helps ensure that the detected edges are continuous.
\end{itemize}
This approach works very well for high contrast images, particularly those black and white~\Cref{am:cannyexample}. The clear separation between foreground and background elements allows the algorithm to detect distinct gradient changes and create clean, continuous edge lines.

As for the similarly coloured golf course images, it can often find the outlines but they are made up of many smaller lines~\Cref{am:CannyGolfCourse}. This fragmentation occurs because the subtle color transitions between different areas of the golf course (like fairways, roughs, and greens) create weaker gradient signals that may fall inconsistently above or below the detection thresholds.

It may appear there is a simple solution to this problem; join the connected lines into one, however this proves to be rather problematic in itself for a number of reasons:
\begin{enumerate}
	\item The desired line does not form a complete shape - Gaps in the detected edges mean that even sophisticated line-joining algorithms may fail to connect all segments belonging to a single boundary

	\item The line is connected to other lines outside the desired shape - Many detected edges from shadows, texture variations, or other regions of the golf course can intersect with the boundary edges required to be isolated, creating unwanted connection points

	\item Once lines are connected, it is impossible to tell which collection of lines is needed - Without prior knowledge of the expected shape or additional contextual information, there's no reliable way to determine which edge segments represent meaningful boundaries, like the edge of a green compared to an outline of trees or a rough area.
\end{enumerate}
All of these means use of canny edge detection can often cause more problems than it solves, while it may have more accurate outlines in places, they may be connected to unwanted areas, Or they may not be complete and still require further user input to chose a selection or finish a shape.

\subsubsection{Machine Learning Approach}
Another possible solution to this problem is to use a machine learning network to predict the areas of the golf course instead.
PyTorch \citep{paszke2019pytorch} is a powerful open-source machine learning library and has become one of the most popular frameworks for deep learning research and production applications since its initial release in 2016.
It was developed to show that usability and speed can both be present in a python implementation of machine learning making it the perfect tool for this task.




\subsubsection{Data Set}
A models training data needs to be closely related to its real world input data, for the Robot Mower that is satelite images or orthophotos from above the desired mowing area.
Training data also needs to be clearly and consistently annotated to producde accurate, reliable results in practice.
The only orthophoto data set publicly available is the danish golf course data set, but it lacks quality and consistency; the outlines do not cover the whole area of single sections and often are missing entirely.
Upon testing the data, it produced faulty results including both true negative and false positives. ~\Crefrange{am:AGDanish}{am:ohGCDanish}

A custom data set was needed, or at least custom annotations of the plain images from the Danish data set since the raw images from the data set are still good quality, high resolution images and are suitable for training purposes with correct annotations
\subsubsection{Training}
Pytorch has several training parameters each with their own effect on the outcome


\section{Performance Evaluation}
%
% Could be a section each for implementation and evaluation if this suits you better or you could use subsections instead. The difference between this section and the previous "Methodology" section is that this one covers "action" or in other words your active contributions to the project. These may include:
% \begin{itemize}
% 	\item Implementation of programming code: Describe your final code architecture using for example (UML) diagrams and code snippets. Make sure that code snippet (figure) captions are self-explanatory which means that you should not have to consult the text body to understand what is shown in the figure. Many code snippets of the same kind should end up in an appendix instead.
% 	\item Results from experiments run, including testing (user and software). Use figures and tables with self-explanatory captions (see earlier statement). Multiple figures and tables that cover several pages should be put in an appendix.
% 	\item Analysis of results: Discuss your experimental and/or test findings in depth. Compare them against other studies and/or benchmarks, and point out limitations of your work (that could be due to limited time) and elaborate on scope for improvement.
% \end{itemize}

\subsection{Map Generation}
\subsection{Complete Coverage Path Planning}
\subsection{Aerail Map Generation}


\section{Conclusion and Future Work}


Another essential section that should keep its title as suggested. Briefly discuss your main findings, outcomes, results; what worked and what could have been done differently. Then summarise your work in a concluding statement by comparing your outcomes against the main and sub-objectives and/or MoSCoW requirements (if used) and suggest potential future work that could be done if more time would be available.


\clearpage

\bibliography{reportbib}

\appendix
\clearpage

\section{Map Generation}

\begin{algorithm}[h!]
	\caption{Point Class Definition}
	\label{mg:point class}
	\begin{algorithmic}[1]
		\Procedure{class Point}{}
		\State $X \gets -1$ \Comment{X-coordinate initialized to -1}
		\State $Y \gets -1$ \Comment{Y-coordinate initialized to -1}
		\State $angle \gets -10$ \Comment{Angle initialized to -10}
		\Procedure{Constructor}{$x$, $y$}
		\State $this.X \gets x$
		\State $this.Y \gets y$
		\State $this.angle \gets -10$ \Comment{Default angle value}
		\EndProcedure
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
	\caption{Generate random points}
	\label{mg:genPoints}
	\begin{algorithmic}[1]
		\Function{GenPoints}{$num$, $P$, $size$}
		\State $points \gets []$
		\For{$i \gets 0$ \textbf{to} $num - 1$}
		\State $randX \gets \text{random\_integer}(P.X + 1, P.X + size)$
		\State $randY \gets \text{random\_integer}(P.Y + 1, P.Y + size)$
		\State $points.\text{append}(\text{Point}(randX, randY))$
		\EndFor
		\State \Return $points$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
	\caption{Sort points by polar angle to origin}
	\label{mg:sortPoints}
	\begin{algorithmic}[1]
		\Function{SortPoints}{$points$, $origin$}
		\State $hull \gets [origin]$
		\State Sort $points$ by Y-coordinate
		\For{$i \gets 0$ \textbf{to} $\text{length}(points) - 1$}
		\State $points[i].angle \gets$ \Call{CalcAngle}{$origin$, $points[i]$}
		\EndFor
		\State Sort $points$ by angle
		\State Append $points$ to $hull$
		\State \Return $hull$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
	\caption{Main function}
	\label{mg:main}
	\begin{algorithmic}[1]
		\Function{Main}{}
		\State $hull \gets []$
		\State $origin \gets \text{Point}(20, 20)$
		\State $field \gets$ \Call{GenPoints}{$20$, $origin$, $400$}
		\State $hull.\text{append}($\Call{SortPoints}{$field$, $origin$}$)$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h!]
	\caption{Main function with holes in shape}
	\label{mg:mainWithHoles}
	\begin{algorithmic}[1]
		\Procedure{Main}{}
		\State $hull \gets$ empty list

		\State $origin \gets \text{Point}(20, 20)$
		\State $field \gets \text{GenPoints}(20, origin, 400)$
		\State add $\text{SortPoints}(field, origin)$ to $hull$

		\State $hole1Base \gets \text{Point}(100, 100)$
		\State $hole1Points \gets \text{GenPoints}(5, hole1Base, 50)$
		\State add $\text{SortPoints}(hole1Points, hole1Base)$ to $hull$

		\State $hole2Base \gets \text{Point}(150, 50)$
		\State $hole2Points \gets \text{GenPoints}(3, hole2Base, 30)$
		\State add $\text{SortPoints}(hole2Points, hole2Base)$ to $hull$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}


\clearpage
\section{Aerial Mapping}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{./images/openCvCannyExample.jpg}
    \caption{Opencv example of canny detection, source \citep{opencv_library} docs}
	\label{am:cannyexample}
\end{figure}


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{./images/openCvCannyGolfCourse.png}
	\caption{OpenCV canny edge detection on an image of a golf course}
	\label{am:CannyGolfCourse}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{./images/AdobeGolf_visualisation.png}
	\caption{An example ouput of pytorch model trained on the Danish Golf Course data set}
	\label{am:AGDanish}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{./images/overheadGolfCourse_visualisation.png}
	\caption{An example ouput of pytorch model trained on the Danish Golf Course data set}
	\label{am:ohGCDanish}
\end{figure}
\end{document}

